# lightning.pytorch==2.1.3
seed_everything: false
eval_after_fit: true
trainer:
  accelerator: gpu
  devices: 1
  precision: 16-mixed
  max_epochs: 75
  logger:
    class_path: lightning.pytorch.loggers.TensorBoardLogger
    init_args:
      save_dir: logs/lenet
      name: bayesian
      default_hp_metric: false
  callbacks:
    - class_path: torch_uncertainty.callbacks.TUClsCheckpoint
    - class_path: lightning.pytorch.callbacks.LearningRateMonitor
      init_args:
        logging_interval: step
    - class_path: lightning.pytorch.callbacks.EarlyStopping
      init_args:
        monitor: val/cls/Acc
        patience: 1000
        check_finite: true
model:
  model:
    class_path: torch_uncertainty.models.classification.bayesian_lenet
    init_args:
      in_channels: 1
      num_classes: 10
      num_samples: 16
      prior_sigma_1: null
      prior_sigma_2: null
      prior_pi: null
      mu_init: null
      sigma_init: null
      activation: torch.nn.ReLU
      norm: torch.nn.Identity
      groups: 1
      dropout_rate: 0.0
  loss:
    class_path: torch_uncertainty.losses.ELBOLoss
    init_args:
      kl_weight: 0.00002
      inner_loss: torch.nn.CrossEntropyLoss
      num_samples: 3
  num_classes: 10
  is_ensemble: true
data:
  root: ./data
  batch_size: 128
  num_workers: 8
optimizer:
  lr: 0.05
  momentum: 0.9
  weight_decay: 5e-4
  nesterov: true
lr_scheduler:
  class_path: torch.optim.lr_scheduler.MultiStepLR
  init_args:
    milestones:
      - 25
      - 50
    gamma: 0.1
