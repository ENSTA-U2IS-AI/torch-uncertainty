# lightning.pytorch==2.1.3
seed_everything: false
eval_after_fit: true
trainer:
  accelerator: gpu
  devices: 1
  precision: 16-mixed
  max_epochs: 40
  logger:
    class_path: lightning.pytorch.loggers.TensorBoardLogger
    init_args:
      save_dir: logs/boston/mlp/normal
      name: mc_dropout
      default_hp_metric: false
  callbacks:
    - class_path: torch_uncertainty.callbacks.TURegCheckpoint
      init_args:
        probabilistic: true
    - class_path: lightning.pytorch.callbacks.LearningRateMonitor
      init_args:
        logging_interval: step
    - class_path: lightning.pytorch.callbacks.EarlyStopping
      init_args:
        monitor: val/reg/MSE
        patience: 1000
        check_finite: true
model:
  model:
    class_path: torch_uncertainty.models.mc_dropout
    init_args:
      model:
        class_path: torch_uncertainty.models.mlp.mlp
        init_args:
          in_features: 13
          num_outputs: 1
          hidden_dims:
            - 50
          dist_family: normal
          dropout_rate: 0.1
      num_estimators: 10
      on_batch: false
      task: regression
      probabilistic: true
  output_dim: 1
  loss: torch_uncertainty.losses.DistributionNLLLoss
  dist_family: normal
  save_in_csv: true
data:
  root: ./data
  batch_size: 128
  dataset_name: boston
optimizer:
  class_path: torch.optim.Adam
  init_args:
    lr: 5e-3
    weight_decay: 0
