# lightning.pytorch==2.1.3
seed_everything: false
eval_after_fit: true
trainer:
  accelerator: gpu
  precision: bf16-mixed
  max_epochs: 100
  accumulate_grad_batches: 2
  logger:
    class_path: lightning.pytorch.loggers.TensorBoardLogger
    init_args:
      save_dir: logs/muad/unet
      name: batch_ensemble
      default_hp_metric: false
  callbacks:
  - class_path: torch_uncertainty.callbacks.TUSegCheckpoint
  - class_path: lightning.pytorch.callbacks.LearningRateMonitor
    init_args:
      logging_interval: step
model:
  model:
    class_path: torch_uncertainty.models.segmentation.batched_unet
    init_args:
      in_channels: 3
      num_classes: 15
      num_estimators: 4
      bilinear: true
  num_classes: 15
  loss:
    class_path: torch.nn.CrossEntropyLoss
    init_args:
      weight:
        class_path: torch.Tensor
        dict_kwargs:
          data:
          - 4.1712
          - 19.4603
          - 3.2345
          - 49.2588
          - 36.2490
          - 34.0272
          - 47.0651
          - 49.7145
          - 12.4178
          - 48.3962
          - 14.3876
          - 32.8862
          - 5.2729
          - 17.8703
          - 50.4984
  format_batch_fn:
    class_path: torch_uncertainty.transforms.RepeatTarget
    init_args:
      num_repeats: 4
data:
  root: ./data
  batch_size: 16
  crop_size: 256
  eval_ood: true
  eval_size:
  - 512
  - 1024
optimizer:
  class_path: torch.optim.Adam
  init_args:
    lr: 0.001
    weight_decay: 1e-4
lr_scheduler:
  class_path: torch.optim.lr_scheduler.MultiStepLR
  init_args:
    milestones:
    - 20
    - 40
    - 60
    - 80
    gamma: 0.5
